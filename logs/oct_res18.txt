Using optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0.0001
)

Epoch: 0, train Loss: 4.6107 Acc: 0.0696
Epoch: 0, val Loss: 7.9963 Acc: 0.0109
Epoch: 1, train Loss: 3.9986 Acc: 0.1489
Epoch: 1, val Loss: 8.9221 Acc: 0.0086
Epoch: 2, train Loss: 3.6527 Acc: 0.2031
Epoch: 2, val Loss: 10.2360 Acc: 0.0051
Epoch: 3, train Loss: 3.4031 Acc: 0.2468
