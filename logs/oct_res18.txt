Using optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0.0001
)

Epoch: 0, train Loss: 4.6063 Acc: 0.0708
Epoch: 0, val Loss: 3.9835 Acc: 0.1438
Epoch: 1, train Loss: 3.9818 Acc: 0.1492
Epoch: 1, val Loss: 3.3837 Acc: 0.2406
Epoch: 2, train Loss: 3.6423 Acc: 0.2041
Epoch: 2, val Loss: 3.0378 Acc: 0.3008
Epoch: 3, train Loss: 3.4022 Acc: 0.2456
Epoch: 3, val Loss: 2.8614 Acc: 0.3334
Epoch: 4, train Loss: 3.2079 Acc: 0.2831
Epoch: 4, val Loss: 2.6799 Acc: 0.3728
Epoch: 5, train Loss: 3.0532 Acc: 0.3115
Epoch: 5, val Loss: 2.5525 Acc: 0.3997
Epoch: 6, train Loss: 2.9310 Acc: 0.3339
Epoch: 6, val Loss: 2.4567 Acc: 0.4170
